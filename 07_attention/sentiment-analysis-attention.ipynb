{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Sentiment Classification: Using Recurrent Neural Networks with Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:36:50.290407Z",
     "start_time": "2019-04-18T18:36:49.391263Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "import d2l\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, rnn, utils as gutils\n",
    "import gluonnlp as nlp\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Sentiment Classification Data\n",
    "\n",
    "###  Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:06.846180Z",
     "start_time": "2019-04-18T18:36:50.292250Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "23"
    }
   },
   "outputs": [],
   "source": [
    "vocab, train_iter, test_iter = d2l.load_data_imdb(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Print the shape of the first mini-batch of data and the number of mini-batches in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:20.138763Z",
     "start_time": "2019-04-18T18:37:20.125156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (64, 500) y (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('# batches:', 391)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    break\n",
    "'# batches:', len(train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Use a Recurrent Neural Network Model with Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.HybridBlock):\n",
    "    def __init__(self, num_atention_units, num_attention_channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.proj_query = nn.Dense(num_atention_units, activation='tanh', flatten=False)\n",
    "            self.parametric_key = nn.Dense(num_attention_channels, activation=None, flatten=False)\n",
    "\n",
    "    def hybrid_forward(self, F, query):\n",
    "        # query shape: [batch_size, seq_len, embedding_width]\n",
    "        # projected query shape: [batch_size, seq_len, num_atention_units]\n",
    "        query = self.proj_query(query)\n",
    "        # scores shape: [batch_size, seq_len, attention_channels]\n",
    "        scores = self.parametric_key(query)\n",
    "\n",
    "        # attention_weights shape: [batch_size,  att_hops, seq_len]\n",
    "        attention_weights = F.softmax(F.transpose(scores, axes=(0, 2, 1)), axis=-1)\n",
    "        # output shape [batch_size, att_hops, embedding_width]\n",
    "        output = F.batch_dot(attention_weights, query)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class AttentiveBiLSTM(nn.HybridBlock):\n",
    "    \"\"\"Lin et al.: A Structured Self-Attentive Sentence Embedding. ICLR 2017\"\"\"\n",
    "    def __init__(self, vocab_len, embed_size, num_hiddens, num_layers,\n",
    "                 num_attention_units, num_attention_channels, **kwargs):\n",
    "        super(AttentiveBiLSTM, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.embedding = nn.Embedding(vocab_len, embed_size)\n",
    "            self.encoder = rnn.LSTM(num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "            self.attention = SelfAttention(num_attention_units, num_attention_channels)\n",
    "            self.decoder = nn.Dense(2)\n",
    "\n",
    "    def hybrid_forward(self, F, inputs):\n",
    "        # The shape of inputs is (batch size, number of words). Because LSTM\n",
    "        # needs to use sequence as the first dimension, the input is\n",
    "        # transformed and the word feature is then extracted. The output shape\n",
    "        # is (number of words, batch size, word vector dimension).\n",
    "        embeddings = self.embedding(F.transpose(inputs))\n",
    "        # The shape of states is (number of words, batch size, 2 * number of\n",
    "        # hidden units).\n",
    "        states = self.encoder(embeddings)\n",
    "        context_vec, att_weights = self.attention(F.transpose(states, (1, 0, 2)))\n",
    "        \n",
    "        outputs = self.decoder(F.flatten(context_vec))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:25.447434Z",
     "start_time": "2019-04-18T18:37:20.149858Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, ctx = 100, 100, 2, d2l.try_all_gpus()\n",
    "natt_unit, natt_channel = 500, 2\n",
    "\n",
    "net = AttentiveBiLSTM(len(vocab), embed_size, num_hiddens, num_layers,\n",
    "                            natt_unit, natt_channel)\n",
    "net.initialize(init.Xavier(), ctx=ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentiveBiLSTM(\n",
       "  (embedding): Embedding(49339 -> 100, float32)\n",
       "  (encoder): LSTM(None -> 100, TNC, num_layers=2, bidirectional)\n",
       "  (attention): SelfAttention(\n",
       "    (proj_query): Dense(None -> 500, Activation(tanh))\n",
       "    (parametric_key): Dense(None -> 2, linear)\n",
       "  )\n",
       "  (decoder): Dense(None -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Pre-trained Word Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.206184Z",
     "start_time": "2019-04-18T18:37:25.449068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49339, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding = nlp.embedding.create('glove', source='glove.6B.100d')\n",
    "idx_to_vec = glove_embedding[vocab.idx_to_token]\n",
    "idx_to_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use these word vectors as feature vectors for each word in the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.210859Z",
     "start_time": "2019-04-18T18:37:40.207714Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(idx_to_vec)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.801349Z",
     "start_time": "2019-04-18T18:37:40.212205Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on [gpu(0)]\n",
      "epoch 1, loss 0.4950, train acc 0.751, test acc 0.831, time 42.9 sec\n",
      "epoch 2, loss 0.3545, train acc 0.846, test acc 0.854, time 42.8 sec\n",
      "epoch 3, loss 0.3073, train acc 0.870, test acc 0.868, time 42.7 sec\n",
      "epoch 4, loss 0.2863, train acc 0.880, test acc 0.872, time 42.5 sec\n",
      "epoch 5, loss 0.2465, train acc 0.899, test acc 0.873, time 42.8 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "d2l.train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.806821Z",
     "start_time": "2019-04-18T18:41:09.802933Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "49"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    sentence = nd.array(vocab[sentence.split()], ctx=d2l.try_gpu())\n",
    "    label = nd.argmax(net(sentence.reshape((1, -1))), axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, use the trained model to classify the sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.814658Z",
     "start_time": "2019-04-18T18:41:09.808150Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.821180Z",
     "start_time": "2019-04-18T18:41:09.816015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
